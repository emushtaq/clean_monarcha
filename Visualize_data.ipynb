{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Monarcha dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "%matplotlib inline\n",
    "import csv\n",
    "import sqlite3\n",
    "import os\n",
    "import re\n",
    "import errno\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from pylab import *\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_dataset = \"/home/mushtaq/monarcha/MonarchaData/\"\n",
    "path_organized_dataset = \"organized_data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef make_list_of_persons(path):\\n        output = [dI for dI in os.listdir(path) if os.path.isdir(os.path.join(path, dI))]\\n        return output\\n\\ndef gather_files(type_of_data, person):\\n        print(\"%%%%%%%%%%%  Gathering files for \" + person + \"    %%%%%%%%%%%%%%%%%%%\")\\n        retrieved_files = []\\n        for root, dirs, files in os.walk(path_dataset + person):\\n                for name in files:\\n                        if name.find(type_of_data) != -1:\\n                                retrieved_files.append(root + \"/\" + name)\\n        create_file(retrieved_files, person, type_of_data)\\n\\ndef create_file(files, person, type_of_data):\\n        print(\"%%%%%%%%%%%  Creating a file for \" + person + \" data:\" + type_of_data  + \"    %%%%%%%%%%%%%%%%%%%\")\\n        if not os.path.exists(path_organized_dataset + person):\\n                os.makedirs(path_organized_dataset + person)\\n\\n        output = open(path_organized_dataset + person + \"/\" + type_of_data  + \".txt\", \"a+\")\\n        for filename in files:\\n                with open(filename) as file:\\n                        for line in file:\\n                                if not line.startswith(\"%\"):\\n                                        line = re.split(\"\\\\s+\", line)\\n                                        line = \",\".join(line)\\n                                        line = line[:-1]\\n                                        line = line + \"\\n\"\\n                                        output.write(line)\\n                                        \\n#generator to cleanup blank lines\\ndef nonblank_lines(f):\\n        for l in f:\\n                line = l.rstrip()\\n                if line:\\n                        yield line\\n                                        \\ndef start():                                                                                                              │[I 13:43:56.911 NotebookApp] Saving file at /TSNE.ipynb\\n        persons = make_list_of_persons(path_dataset)                                                                      │[I 13:44:04.842 NotebookApp] Saving file at /TSNE.ipynb\\n        data_points = [\"META\", \"MAG\", \"ACC\", \"WIFI\", \"LOC\", \"BAT\", \"BLTH\"]                                                │[I 13:45:23.222 NotebookApp] Saving file at /TSNE.ipynb\\n        for person in persons:                                                                                            │[I 13:47:23.209 NotebookApp] Saving file at /TSNE.ipynb\\n                for data_point in data_points:                                                                            │[I 13:49:23.821 NotebookApp] Saving file at /TSNE.ipynb\\n                        gather_files(data_point, person)      \\n\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Methods to organize data into folders for each person. Features are organized into separate files in these folders\n",
    "'''\n",
    "\n",
    "'''\n",
    "def make_list_of_persons(path):\n",
    "        output = [dI for dI in os.listdir(path) if os.path.isdir(os.path.join(path, dI))]\n",
    "        return output\n",
    "\n",
    "def gather_files(type_of_data, person):\n",
    "        print(\"%%%%%%%%%%%  Gathering files for \" + person + \"    %%%%%%%%%%%%%%%%%%%\")\n",
    "        retrieved_files = []\n",
    "        for root, dirs, files in os.walk(path_dataset + person):\n",
    "                for name in files:\n",
    "                        if name.find(type_of_data) != -1:\n",
    "                                retrieved_files.append(root + \"/\" + name)\n",
    "        create_file(retrieved_files, person, type_of_data)\n",
    "\n",
    "def create_file(files, person, type_of_data):\n",
    "        print(\"%%%%%%%%%%%  Creating a file for \" + person + \" data:\" + type_of_data  + \"    %%%%%%%%%%%%%%%%%%%\")\n",
    "        if not os.path.exists(path_organized_dataset + person):\n",
    "                os.makedirs(path_organized_dataset + person)\n",
    "\n",
    "        output = open(path_organized_dataset + person + \"/\" + type_of_data  + \".txt\", \"a+\")\n",
    "        for filename in files:\n",
    "                with open(filename) as file:\n",
    "                        for line in file:\n",
    "                                if not line.startswith(\"%\"):\n",
    "                                        line = re.split(\"\\s+\", line)\n",
    "                                        line = \",\".join(line)\n",
    "                                        line = line[:-1]\n",
    "                                        line = line + \"\\n\"\n",
    "                                        output.write(line)\n",
    "                                        \n",
    "#generator to cleanup blank lines\n",
    "def nonblank_lines(f):\n",
    "        for l in f:\n",
    "                line = l.rstrip()\n",
    "                if line:\n",
    "                        yield line\n",
    "                                        \n",
    "def start():                                                                                                              │[I 13:43:56.911 NotebookApp] Saving file at /TSNE.ipynb\n",
    "        persons = make_list_of_persons(path_dataset)                                                                      │[I 13:44:04.842 NotebookApp] Saving file at /TSNE.ipynb\n",
    "        data_points = [\"META\", \"MAG\", \"ACC\", \"WIFI\", \"LOC\", \"BAT\", \"BLTH\"]                                                │[I 13:45:23.222 NotebookApp] Saving file at /TSNE.ipynb\n",
    "        for person in persons:                                                                                            │[I 13:47:23.209 NotebookApp] Saving file at /TSNE.ipynb\n",
    "                for data_point in data_points:                                                                            │[I 13:49:23.821 NotebookApp] Saving file at /TSNE.ipynb\n",
    "                        gather_files(data_point, person)      \n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOF while scanning triple-quoted string literal (<ipython-input-1-87c42b0a1c29>, line 32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-87c42b0a1c29>\"\u001b[0;36m, line \u001b[0;32m32\u001b[0m\n\u001b[0;31m    plt.show()\u001b[0m\n\u001b[0m              \n^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOF while scanning triple-quoted string literal\n"
     ]
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "def plot():\n",
    "        with open(\"organized_data/p0101/ACC.txt\", \"r+\") as file:\n",
    "                for line in nonblank_lines(file):\n",
    "                        print(line)\n",
    "\n",
    "def load():\n",
    "        sensor_time, timestamp, x,y,z = np.loadtxt(\"organized_data/p2101/ACC.txt\", delimiter= ',', unpack=True)\n",
    "        #sensor_time, timestamp, x,y,z = np.loadtxt(\"test_acc.txt\", unpack=True)\n",
    "        timestamp = timestamp / 1000\n",
    "        timestamp = mdates.epoch2num(timestamp)\n",
    "        #print(\"timestamps:\")\n",
    "        #print(timestamp)\n",
    "        plot_data(timestamp, x)\n",
    "\n",
    "def plot_data(timestamp, data):\n",
    "        fig, ax = plt.subplots()\n",
    "\n",
    "        ax.plot_date(timestamp, data)\n",
    "\n",
    "        # Choose your xtick format string\n",
    "        date_fmt = '%d-%m-%y %H:%M:%S'\n",
    "\n",
    "        # Use a DateFormatter to set the data to the correct format.\n",
    "        date_formatter = mdates.DateFormatter(date_fmt)\n",
    "        ax.xaxis.set_major_formatter(date_formatter)\n",
    "\n",
    "        # Sets the tick labels diagonal so they fit easier.\n",
    "        fig.autofmt_xdate()\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Wrong number of columns at line 48267",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-28bc69680054>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Completed.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-28bc69680054>\u001b[0m in \u001b[0;36mstart\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m         \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#       persons = make_list_of_persons(path_dataset)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#       data_points = [\"META\", \"MAG\", \"ACC\", \"WIFI\", \"LOC\", \"BAT\", \"BLTH\"]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#       for person in persons:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-4ba124762837>\u001b[0m in \u001b[0;36mload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m '''\n\u001b[1;32m     13\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0msensor_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"organized_data/p2101/ACC.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munpack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;31m#sensor_time, timestamp, x,y,z = np.loadtxt(\"test_acc.txt\", unpack=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mtimestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimestamp\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin)\u001b[0m\n\u001b[1;32m    980\u001b[0m                 \u001b[0mline_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mskiprows\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m                 raise ValueError(\"Wrong number of columns at line %d\"\n\u001b[0;32m--> 982\u001b[0;31m                                  % line_num)\n\u001b[0m\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m             \u001b[0;31m# Convert each value according to its column and store\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Wrong number of columns at line 48267"
     ]
    }
   ],
   "source": [
    "def start():\n",
    "        load()\n",
    "#       persons = make_list_of_persons(path_dataset)\n",
    "#       data_points = [\"META\", \"MAG\", \"ACC\", \"WIFI\", \"LOC\", \"BAT\", \"BLTH\"]\n",
    "#       for person in persons:\n",
    "#               for data_point in data_points:\n",
    "#                       gather_files(data_point, person)\n",
    "\n",
    "\n",
    "\n",
    "start()\n",
    "print(\"Completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
